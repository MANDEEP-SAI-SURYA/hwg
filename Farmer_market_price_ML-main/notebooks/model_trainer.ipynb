{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Random Forest Regression -----\n",
      "R2 Score: 0.9253205705440292\n",
      "Mean Absolute Error: 183.40730519480522\n",
      "Mean Squared Error: 50941.98953409091\n",
      "Root Mean Squared Error: 225.70332193853707\n",
      "\n",
      "Confusion Matrix (Binned) - Random Forest Regression\n",
      "Predicted Bin   0   1   2   3   4\n",
      "Actual Bin                       \n",
      "0              49  10   0   0   0\n",
      "1               1  81  13   0   0\n",
      "2               0   8  34  21   0\n",
      "3               0   0   8  35  18\n",
      "4               0   0   0   8  22\n",
      "✅ Model and encoders saved successfully in: C:\\Users\\VINIL\\Desktop\\Market_price_ML\\flask_app\\models\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import traceback\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Setup logging\n",
    "log_folder = \"logs\"\n",
    "os.makedirs(log_folder, exist_ok=True)\n",
    "log_file = os.path.join(log_folder, \"crop_price_prediction.log\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=log_file,\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "def log_exception():\n",
    "    \"\"\"Logs the last exception with traceback info.\"\"\"\n",
    "    exc_info = traceback.format_exc()\n",
    "    logging.error(f\"Exception occurred: {exc_info}\")\n",
    "\n",
    "try:\n",
    "    # Load dataset\n",
    "    dataset_path = \"India_Crop_Price_Prediction_Dataset.csv\"\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    logging.info(\"Dataset loaded successfully.\")\n",
    "    df = df.drop(columns=['Year'])\n",
    "    # Features and target\n",
    "    X = df.drop(columns=[\"Next_Year_Price\"])\n",
    "    y = df[\"Next_Year_Price\"]\n",
    "    logging.info(\"Features and target variable separated.\")\n",
    "\n",
    "    # Identify categorical and numerical columns\n",
    "    categorical_cols = [\"Crop\", \"Region\"]\n",
    "    numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "    logging.info(f\"Categorical columns: {categorical_cols}\")\n",
    "    logging.info(f\"Numerical columns: {numerical_cols}\")\n",
    "\n",
    "    # Preprocessing for numerical and categorical data\n",
    "    numeric_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Random Forest Regression pipeline\n",
    "    rf_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    logging.info(\"Data split into training and testing sets.\")\n",
    "\n",
    "    # Train Random Forest Regression\n",
    "    rf_pipeline.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_pipeline.predict(X_test)\n",
    "    logging.info(\"Random Forest Regression model trained and predictions made.\")\n",
    "\n",
    "    # Evaluation function\n",
    "    def evaluate_model(y_true, y_pred, model_name):\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        logging.info(f\"{model_name} - R2: {r2:.4f}, MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "        print(f\"\\n----- {model_name} -----\")\n",
    "        print(\"R2 Score:\", r2)\n",
    "        print(\"Mean Absolute Error:\", mae)\n",
    "        print(\"Mean Squared Error:\", mse)\n",
    "        print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "    # Evaluate Random Forest Regression\n",
    "    evaluate_model(y_test, y_pred_rf, \"Random Forest Regression\")\n",
    "\n",
    "    # Confusion matrix equivalent for regression (using bins)\n",
    "    def regression_confusion_matrix(y_true, y_pred, bins=5, model_name=\"Model\"):\n",
    "        y_true_binned = pd.cut(y_true, bins=bins, labels=False)\n",
    "        y_pred_binned = pd.cut(y_pred, bins=bins, labels=False)\n",
    "\n",
    "        conf_matrix = pd.crosstab(y_true_binned, y_pred_binned, rownames=['Actual Bin'], colnames=['Predicted Bin'])\n",
    "\n",
    "        logging.info(f\"{model_name} - Regression confusion matrix:\\n{conf_matrix}\")\n",
    "\n",
    "        print(f\"\\nConfusion Matrix (Binned) - {model_name}\")\n",
    "        print(conf_matrix)\n",
    "\n",
    "    regression_confusion_matrix(y_test, y_pred_rf, bins=5, model_name=\"Random Forest Regression\")\n",
    "\n",
    "    # ---------- SAVE MODEL AND PREPROCESSORS SEPARATELY ---------- #\n",
    "\n",
    "    # Folder to save models\n",
    "    models_folder = r\"C:\\Users\\VINIL\\Desktop\\Market_price_ML\\flask_app\\models\"\n",
    "    os.makedirs(models_folder, exist_ok=True)\n",
    "\n",
    "    # Define file paths\n",
    "    model_path = os.path.join(models_folder, \"random_forest_model.pkl\")\n",
    "    encoder_path = os.path.join(models_folder, \"onehot_encoder.pkl\")\n",
    "    scaler_path = os.path.join(models_folder, \"standard_scaler.pkl\")\n",
    "\n",
    "    # Extract trained components from the pipeline\n",
    "    trained_preprocessor = rf_pipeline.named_steps['preprocessor']\n",
    "    trained_numeric_scaler = trained_preprocessor.named_transformers_['num']\n",
    "    trained_categorical_encoder = trained_preprocessor.named_transformers_['cat']\n",
    "\n",
    "    trained_rf_model = rf_pipeline.named_steps['regressor']\n",
    "\n",
    "    # Save Random Forest model\n",
    "    with open(model_path, \"wb\") as model_file:\n",
    "        pickle.dump(trained_rf_model, model_file)\n",
    "\n",
    "    # Save the OneHotEncoder\n",
    "    with open(encoder_path, \"wb\") as encoder_file:\n",
    "        pickle.dump(trained_categorical_encoder, encoder_file)\n",
    "\n",
    "    # Save the StandardScaler\n",
    "    with open(scaler_path, \"wb\") as scaler_file:\n",
    "        pickle.dump(trained_numeric_scaler, scaler_file)\n",
    "\n",
    "    logging.info(\"✅ Random Forest model and preprocessing objects saved successfully.\")\n",
    "    print(\"✅ Model and encoders saved successfully in:\", models_folder)\n",
    "\n",
    "except Exception as e:\n",
    "    log_exception()\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
